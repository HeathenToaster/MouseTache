{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook allows to follow all the processing perfromed in the Behavioral_Analysis notebook ( which run behavioral_analysis functions)\n",
    "It sometimes try to clarify some potential complications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib.path import Path\n",
    "from scipy.ndimage import gaussian_filter as smooth\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import glob\n",
    "\n",
    "from processing_TowerCoordinates import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 mice in the data folder: MOU2329, MOU2330, MOU2331, MOU2332, MOU2333, MOU2334\n",
      "\n",
      "Hello, I'm MOU2329! I have foraged for 18 sessions:\n",
      "['MOU2329_20240607-1315', 'MOU2329_20240607-1714', 'MOU2329_20240610-0936', 'MOU2329_20240610-1336', 'MOU2329_20240611-0915', 'MOU2329_20240611-1324', 'MOU2329_20240612-0918', 'MOU2329_20240612-1341', 'MOU2329_20240613-0914', 'MOU2329_20240613-1405', 'MOU2329_20240614-0820', 'MOU2329_20240614-1331', 'MOU2329_20240617-0829', 'MOU2329_20240617-1420', 'MOU2329_20240618-0829', 'MOU2329_20240618-1451', 'MOU2329_20240619-0828', 'MOU2329_20240619-1406'] \n",
      "\n",
      "Hello, I'm MOU2330! I have foraged for 18 sessions:\n",
      "['MOU2330_20240607-1335', 'MOU2330_20240607-1733', 'MOU2330_20240610-0956', 'MOU2330_20240610-1357', 'MOU2330_20240611-0936', 'MOU2330_20240611-1342', 'MOU2330_20240612-0937', 'MOU2330_20240612-1400', 'MOU2330_20240613-0933', 'MOU2330_20240613-1424', 'MOU2330_20240614-0840', 'MOU2330_20240614-1351', 'MOU2330_20240617-0848', 'MOU2330_20240617-1438', 'MOU2330_20240618-0848', 'MOU2330_20240618-1509', 'MOU2330_20240619-0846', 'MOU2330_20240619-1424'] \n",
      "\n",
      "Hello, I'm MOU2331! I have foraged for 18 sessions:\n",
      "['MOU2331_20240607-1235', 'MOU2331_20240607-1606', 'MOU2331_20240610-1017', 'MOU2331_20240610-1427', 'MOU2331_20240611-1026', 'MOU2331_20240611-1419', 'MOU2331_20240612-1002', 'MOU2331_20240612-1427', 'MOU2331_20240613-0959', 'MOU2331_20240613-1449', 'MOU2331_20240614-0905', 'MOU2331_20240614-1416', 'MOU2331_20240617-0932', 'MOU2331_20240617-1500', 'MOU2331_20240618-0910', 'MOU2331_20240618-1532', 'MOU2331_20240619-0907', 'MOU2331_20240619-1447'] \n",
      "\n",
      "Hello, I'm MOU2332! I have foraged for 18 sessions:\n",
      "['MOU2332_20240607-1253', 'MOU2332_20240607-1627', 'MOU2332_20240610-1037', 'MOU2332_20240610-1448', 'MOU2332_20240611-1048', 'MOU2332_20240611-1437', 'MOU2332_20240612-1021', 'MOU2332_20240612-1446', 'MOU2332_20240613-1018', 'MOU2332_20240613-1508', 'MOU2332_20240614-0924', 'MOU2332_20240614-1434', 'MOU2332_20240617-0911', 'MOU2332_20240617-1518', 'MOU2332_20240618-0928', 'MOU2332_20240618-1549', 'MOU2332_20240619-0925', 'MOU2332_20240619-1506'] \n",
      "\n",
      "Hello, I'm MOU2333! I have foraged for 18 sessions:\n",
      "['MOU2333_20240607-1151', 'MOU2333_20240607-1524', 'MOU2333_20240610-1103', 'MOU2333_20240610-1557', 'MOU2333_20240611-1118', 'MOU2333_20240611-1502', 'MOU2333_20240612-1044', 'MOU2333_20240612-1512', 'MOU2333_20240613-1050', 'MOU2333_20240613-1532', 'MOU2333_20240614-0956', 'MOU2333_20240614-1456', 'MOU2333_20240617-1000', 'MOU2333_20240617-1539', 'MOU2333_20240618-0952', 'MOU2333_20240618-1611', 'MOU2333_20240619-0947', 'MOU2333_20240619-1527'] \n",
      "\n",
      "Hello, I'm MOU2334! I have foraged for 18 sessions:\n",
      "['MOU2334_20240607-1213', 'MOU2334_20240607-1544', 'MOU2334_20240610-1126', 'MOU2334_20240610-1620', 'MOU2334_20240611-1138', 'MOU2334_20240611-1520', 'MOU2334_20240612-1104', 'MOU2334_20240612-1531', 'MOU2334_20240613-1108', 'MOU2334_20240613-1550', 'MOU2334_20240614-1015', 'MOU2334_20240614-1515', 'MOU2334_20240617-1018', 'MOU2334_20240617-1558', 'MOU2334_20240618-1009', 'MOU2334_20240618-1629', 'MOU2334_20240619-1005', 'MOU2334_20240619-1545'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the path_to_data_folder is the path of the folder where you store your different mice.\n",
    "\n",
    "# Windows:\n",
    "# path_to_data_folder='C:'+os.sep+'Users'+os.sep+'MORVAN'+os.sep+'Documents'+os.sep+'patchouris'+os.sep+'Sample_Data'+os.sep\n",
    "# Linux:\n",
    "# path_to_data_folder '/home/david/Documents/Code/ForagingProject/Patchouris/patchouris/Sample_Data/'\n",
    "# MacOs\n",
    "#path_to_data_folder = '/Users/davidrobbe/Documents/Science/Data/ForagingMice/'\n",
    "\n",
    "\n",
    "#path_to_data_folder='/home/david/Documents/David/Data/'\n",
    "path_to_data_folder='/LocalData/ForagingMice/JAK2Data'\n",
    "#path_to_data_folder='/LocalData/ForagingMice/MaudData'\n",
    "\n",
    "#path_to_data_folder = '/Users/davidrobbe/Documents/Science/Data/ForagingMice/'\n",
    "\n",
    "\n",
    "pattern_of_MOU_Folders = os.path.join(path_to_data_folder, \"MOU*\")\n",
    "\n",
    "# List all mice in the data folder (If you want to process all the mice in your data folder),\n",
    "mice_list = [os.path.basename(path) for path in glob.glob(pattern_of_MOU_Folders)]\n",
    "mice_list=sorted(mice_list)\n",
    "\n",
    "# Print the number of mice, the list of mice, and add an empty line\n",
    "print(f'Found {len(mice_list)} {\"mice\" if len(mice_list) > 1 else \"mouse\"} in the data folder: {\", \".join(mice_list)}\\n')\n",
    "\n",
    "\n",
    "#If you want to process a subset of mice uncomment the line below and comment the 2 lines above\n",
    "\n",
    "#mice_list: list[str] = [\"MOU2334\"]  # For processing  a single mice. Equivalent to mice_list = [\"MOU2334\"] but more correct as it forces to create a list of string\n",
    "#mice_list=['MOU2329', 'MOU2330', 'MOU2331', 'MOU2332', 'MOU2333', 'MOU2334']\n",
    "#print(f'Found {len(mice_list)} {\"mice\" if len(mice_list) > 1 else \"mouse\"} in the data folder:')\n",
    "\n",
    "session_list = {}\n",
    "for mouse in mice_list:\n",
    "    mouse_folder = os.path.join(path_to_data_folder,mouse)\n",
    "    session_list[mouse] = sorted([name for name in os.listdir(mouse_folder)\n",
    "                           if os.path.isdir(os.path.join(mouse_folder, name))\n",
    "                           and name.startswith('MOU')])\n",
    "    nb_sessions = len(session_list[mouse])\n",
    "    print(f'Hello, I\\'m {mouse}! I have foraged for {nb_sessions} sessions:')\n",
    "    print(session_list[mouse], '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just print the list of mice, the dictionnany of sessions across mice and then we will choose a single mice and single session for illustration purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/LocalData/ForagingMice/JAK2Data/MOU2329\n",
      "MOU2329_20240614-1331\n"
     ]
    }
   ],
   "source": [
    "folder_path_mouse_to_process=os.path.join(path_to_data_folder,mice_list[0])\n",
    "#folder_path_mouse_to_process=os.path.join(path_to_data_folder,'MOU4624')\n",
    "print(folder_path_mouse_to_process)\n",
    "\n",
    "session_to_process=session_list[mice_list[0]][11]\n",
    "#session_to_process='MOU4624_20240806-1512'\n",
    "print(session_to_process)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. this first part of the code generate the coordinates of the 4 towers and the trapezes around them\n",
    "\n",
    "##### this step involves: \n",
    "##### 1- a tricky vertical symetries due to differential references of the coordinate entered in the aquisition program (ref on the upper left corner in opencv) and in matplotlib (ref on the lower left corner)\n",
    "##### 2- a conversion from pixel to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default towers_coordinates\n",
      "{'NW': [[104, 125], [173, 125], [173, 201], [104, 201]], 'NE': [[330, 120], [400, 120], [400, 200], [330, 200]], 'SW': [[109, 351], [181, 351], [181, 410], [109, 410]], 'SE': [[330, 350], [400, 350], [400, 410], [330, 410]]}\n",
      "Trapeze width from parameter file:\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "trapeze_width, towers_coordinates = get_trapeze_and_tower_data(folder_path_mouse_to_process, session_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NW': {'N': [[19.28, 71.76], [32.08, 71.76], [np.float64(41.35), np.float64(81.03)], [np.float64(10.01), np.float64(81.03)]], 'E': [[32.08, 71.76], [32.08, 57.67], [np.float64(41.35), np.float64(48.4)], [np.float64(41.35), np.float64(81.03)]], 'S': [[32.08, 57.67], [19.28, 57.67], [np.float64(10.01), np.float64(48.4)], [np.float64(41.35), np.float64(48.4)]], 'W': [[19.28, 57.67], [19.28, 71.76], [np.float64(10.01), np.float64(81.03)], [np.float64(10.01), np.float64(48.4)]]}, 'NE': {'N': [[61.19, 72.69], [74.17, 72.69], [np.float64(83.44), np.float64(81.96)], [np.float64(51.92), np.float64(81.96)]], 'E': [[74.17, 72.69], [74.17, 57.85], [np.float64(83.44), np.float64(48.58)], [np.float64(83.44), np.float64(81.96)]], 'S': [[74.17, 57.85], [61.19, 57.85], [np.float64(51.92), np.float64(48.58)], [np.float64(83.44), np.float64(48.58)]], 'W': [[61.19, 57.85], [61.19, 72.69], [np.float64(51.92), np.float64(81.96)], [np.float64(51.92), np.float64(48.58)]]}, 'SW': {'N': [[20.21, 29.85], [33.56, 29.85], [np.float64(42.83), np.float64(39.13)], [np.float64(10.94), np.float64(39.13)]], 'E': [[33.56, 29.85], [33.56, 18.91], [np.float64(42.83), np.float64(9.64)], [np.float64(42.83), np.float64(39.13)]], 'S': [[33.56, 18.91], [20.21, 18.91], [np.float64(10.94), np.float64(9.64)], [np.float64(42.83), np.float64(9.64)]], 'W': [[20.21, 18.91], [20.21, 29.85], [np.float64(10.94), np.float64(39.13)], [np.float64(10.94), np.float64(9.64)]]}, 'SE': {'N': [[61.19, 30.04], [74.17, 30.04], [np.float64(83.44), np.float64(39.31)], [np.float64(51.92), np.float64(39.31)]], 'E': [[74.17, 30.04], [74.17, 18.91], [np.float64(83.44), np.float64(9.64)], [np.float64(83.44), np.float64(39.31)]], 'S': [[74.17, 18.91], [61.19, 18.91], [np.float64(51.92), np.float64(9.64)], [np.float64(83.44), np.float64(9.64)]], 'W': [[61.19, 18.91], [61.19, 30.04], [np.float64(51.92), np.float64(39.31)], [np.float64(51.92), np.float64(9.64)]]}}\n"
     ]
    }
   ],
   "source": [
    "all_trapezes_coordinates_cm, towers_coordinates_cm= generate_trapeze_and_tower_coordinates(towers_coordinates, trapeze_width)\n",
    "print(all_trapezes_coordinates_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. this parts loads the data\n",
    "\n",
    "##### this step involves: \n",
    "##### 1- a tricky vertical symetries due to differential references of the coordinate entered in the aquisition program (ref on the upper left corner in opencv) and in matplotlib (ref on the lower left corner)\n",
    "##### 2- a conversion from pixel to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(mouseFolder_Path, session):\n",
    "    try:\n",
    "        # Gets the parameters of the session\n",
    "        param_df = pd.read_csv(mouseFolder_Path + os.sep + session + os.sep + session + \"_sessionparam.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"File sessionparam not found\")\n",
    "\n",
    "    try:\n",
    "        #Gets the positional informations and filter the dataframe to keep only the relevant informations\n",
    "        csvCentroid_fullpath = mouseFolder_Path + os.sep + session + os.sep + session + '_centroidTXY.csv'\n",
    "        trajectory_df = pd.read_csv(csvCentroid_fullpath) #Transforms CSV file into panda dataframe\n",
    "        trajectory_df = trajectory_df.dropna() #Deletes lines with one or more NA\n",
    "        trajectory_df = trajectory_df.loc[trajectory_df['time'] > 15] #During the first seconds of the video, as the background substraction is still building up, \n",
    "        #                                           #the tracking is innacruate so we don't analyze postions during the first 15 seconds\n",
    "        trajectory_df = trajectory_df[trajectory_df['xposition'].between(1, 500) & trajectory_df['yposition'].between(1, 500)] #The pixel values between 1 and 500 are kept)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File centroidTXY not found\")\n",
    "\n",
    "    try:\n",
    "        csvTurnsinfo_fullpath = mouseFolder_Path + os.sep + session + os.sep + session + '_turnsinfo.csv'  # get the information on the turns in the dataframe turns_df\n",
    "        turns_df = pd.read_csv(csvTurnsinfo_fullpath)  # Transforms CSV file into panda dataframe\n",
    "        for i in range(turns_df.index.values[-1]):  # if there is a missing value for ongoingRewardedObject, replace it with either SW or SE, as long as it's not the one where the mouse is\n",
    "            if type(turns_df['ongoingRewardedObject'][i]) == float:\n",
    "                turns_df.iat[i, 8] = str([turns_df.iat[i, 4]])\n",
    "        turns_df = turns_df.loc[turns_df['time'] > 15]  # same as above #TODO someone you shoud spend some time on the aquisition code to have a pre-loaded background and not loose the beginning\n",
    "    except FileNotFoundError:\n",
    "        print(\"File turnsinfo not found\")\n",
    "\n",
    "    return trajectory_df, turns_df, param_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trajectory(trajectory_df):\n",
    "    # Video and arena dimensions\n",
    "    video_dimension_pixels = (512, 512)\n",
    "    arena_width_cm = 84\n",
    "    arena_width_pixels = 453\n",
    "\n",
    "    # Conversion factor from pixels to cm\n",
    "    conversion_factor = arena_width_cm / arena_width_pixels\n",
    "\n",
    "    # Smoothing parameter\n",
    "    smooth_sigma = 1\n",
    "\n",
    "    # Extract time and positions from the DataFrame\n",
    "    time_video_frames = trajectory_df['time'].to_numpy()\n",
    "    xpositions = trajectory_df['xposition'].to_numpy()\n",
    "    ypositions = trajectory_df['yposition'].to_numpy()\n",
    "\n",
    "    # Correct for OpenCV flipping in y-positions\n",
    "    ypositions = video_dimension_pixels[1] - ypositions\n",
    "\n",
    "    # Smooth positions\n",
    "    smoothed_Xpositions = gaussian_filter1d(xpositions, sigma=smooth_sigma)\n",
    "    smoothed_Ypositions = gaussian_filter1d(ypositions, sigma=smooth_sigma)\n",
    "\n",
    "    # Convert positions from pixels to cm\n",
    "    smoothed_Xpositions_cm = smoothed_Xpositions * conversion_factor\n",
    "    smoothed_Ypositions_cm = smoothed_Ypositions * conversion_factor\n",
    "\n",
    "    # Combine smoothed positions in cm\n",
    "    smoothed_positions_cm = [smoothed_Xpositions_cm, smoothed_Ypositions_cm]\n",
    "\n",
    "    return time_video_frames, smoothed_positions_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute distance, speed, and angular speed in degrees per second. \n",
    "# We only compute angular speed when mice is moving above a certain speed threshold in cm/s\n",
    "def compute_distance_speed_angular_speed(smoothed_positions_cm, time_video_frames, speed_threshold=5):\n",
    "    # Calculate the differences between consecutive points\n",
    "    delta_x = np.diff(smoothed_positions_cm[0])\n",
    "    delta_y = np.diff(smoothed_positions_cm[1])\n",
    "    delta_t = np.diff(time_video_frames)\n",
    "    \n",
    "    # Compute the distances traveled between each timepoint\n",
    "    distances = np.sqrt(delta_x**2 + delta_y**2)\n",
    "    \n",
    "    speeds = distances / delta_t\n",
    "    smooth_sigma = 1 #the sigma used for the remaining of the analysis for smoothing\n",
    "    speeds = gaussian_filter1d(speeds, sigma=smooth_sigma)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Compute the angles between each timepoint\n",
    "    angles = np.arctan2(delta_y, delta_x)\n",
    "    \n",
    "    # Compute the differences between consecutive angles\n",
    "    delta_angles = np.diff(angles)\n",
    "    \n",
    "    # Convert delta_angles from radians to degrees\n",
    "    delta_angles_deg = np.degrees(delta_angles)\n",
    "    \n",
    "    # Ensure angles are within -180 to 180 range\n",
    "    delta_angles_deg = (delta_angles_deg + 180) % 360 - 180\n",
    "    \n",
    "    # Mask speeds below the threshold\n",
    "    valid_mask = speeds > speed_threshold\n",
    "    \n",
    "    # Compute angular speeds in degrees per second\n",
    "    angular_speeds = np.zeros_like(delta_angles_deg)\n",
    "    valid_delta_t = delta_t[1:][valid_mask[1:]]\n",
    "    angular_speeds[valid_mask[1:]] = delta_angles_deg[valid_mask[1:]] / valid_delta_t\n",
    "\n",
    "    # Filter angular speeds to include only those above the threshold\n",
    "    filtered_angular_speeds = angular_speeds[valid_mask[1:]]\n",
    "\n",
    "    distances= np.insert(distances, 0, 0) # insert a 0 to avoid length error with  time_video_frames. We consider that\n",
    "                                            # at the first frame the distance is null\n",
    "    speeds = np.insert(speeds, 0, 0) # insert a 0 to avoid length error with time_video_frames. We consider that\n",
    "                                            # at the first frame the speed is null\n",
    "\n",
    "    \n",
    "    return distances, speeds, filtered_angular_speeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOME PROCESSING HERE\n",
    "# we load the trajectory , turn info and parametres info from the csv files generated by the acqusition software\n",
    "trajectory_df, turns_df, param_df=load_data(folder_path_mouse_to_process,session_to_process)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_video_frames, smoothed_positions_cm=process_trajectory(trajectory_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total distance is: 122.38 m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compute instantaneous distances, speeds, and angular speeds\n",
    "distances, speeds, angular_speeds = compute_distance_speed_angular_speed(smoothed_positions_cm, time_video_frames)\n",
    "\n",
    "\n",
    "# Calculate total distance in m\n",
    "total_distance = np.sum(distances)/100  # Convert cm to m\n",
    "print(f\"The total distance is: {total_distance:.2f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets identified  run epcochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detect_run_epochs(speeds, time_video_frames):\n",
    "    \"\"\"\n",
    "    \n",
    "    Identifies continuous epochs during which the mouse is moving above a certain speed (cut_off_speed).\n",
    "    A minimal duration of low speed is necessary to be considered as the end of a run.\n",
    "    Similarly, a minimal duration of high speed is necessary to be considered as a run.\n",
    "    \"\"\"\n",
    "    \n",
    "    #for this we need some parameters to cut the trajectory into run based on speed, duration of runs and pauses\n",
    "    pause_min_duration = 0.1 #if a stop is shorter than this, merges the two epochs bordering it\n",
    "    run_min_duration = 0.3 #minimal duration of an epoch to be considerd\n",
    "    cut_off_speed = 7 # this value is the speed in cm/s. It is used to detect when the animals stop running. \n",
    "    \n",
    "    \n",
    "    \n",
    "    run_epochs = []\n",
    "    is_in_epoch = False  # Flag to track if we are currently in a running epoch\n",
    "    epoch_start_index = 0\n",
    "\n",
    "    if len(speeds) != len(time_video_frames):\n",
    "        raise ValueError(\"speeds and time_video_frames have different lengths\")\n",
    "\n",
    "    for i in range(len(speeds)):\n",
    "        if speeds[i] >= cut_off_speed:  # Speed above cut-off value\n",
    "            if not is_in_epoch: # if the previous trajectory speed was not part of running epoch then this will be a start of a new epoch\n",
    "                epoch_start_index = i  # Mark the beginning of a new epoch\n",
    "                is_in_epoch = True\n",
    "        else: # the speed of the current data point is below the treshold\n",
    "            if is_in_epoch: # if we were in a run epoch just before (1st point below the treshold)\n",
    "                # Check first if the pause between this epoch's starting point (time_video_frames[epoch_start_index]) and  \n",
    "                # the previous epoch' last point time_video_frames[run_epochs[-1][1]] is shorter than the minimal time for a pause\n",
    "                # then the previous epoch  should be extended to the previous data point.  \n",
    "                if run_epochs and (time_video_frames[epoch_start_index] - time_video_frames[run_epochs[-1][1]] < pause_min_duration):\n",
    "                    run_epochs[-1][1] = i - 1  # Extend the previous epoch\n",
    "                else: # the pause has been long enough then we terminate the run epoch  other previous \n",
    "                    run_epochs.append([epoch_start_index, i - 1])  # Add new epoch\n",
    "                is_in_epoch = False\n",
    "\n",
    "    # Final check for any epoch still in progress\n",
    "    if is_in_epoch:\n",
    "        if run_epochs and (time_video_frames[epoch_start_index] - time_video_frames[run_epochs[-1][1]] < pause_min_duration):\n",
    "            run_epochs[-1][1] = len(speeds) - 1\n",
    "        elif (time_video_frames[-1] - time_video_frames[epoch_start_index]) >= run_min_duration:\n",
    "            run_epochs.append([epoch_start_index, len(speeds) - 1])\n",
    "\n",
    "    # Remove epochs that are too short\n",
    "    run_epochs = [epoch for epoch in run_epochs if (time_video_frames[epoch[1]] - time_video_frames[epoch[0]]) >= run_min_duration]\n",
    "    \n",
    "    # Adjust the start and end of each epoch based on acceleration. The idea is that with the threshold method we miss the beginning and enf of the run\n",
    "    # for the starting point. We are going back and find the point at wich the animal acceleration is less than 40% \n",
    "    # than the acceleration at the moment at which he passed the treshold. \n",
    "    clean_run_epochs = [None] * len(run_epochs)\n",
    "    for index,epoch in enumerate(run_epochs):\n",
    "        clean_run_epochs[index] = epoch.copy()\n",
    "        epoch_start, epoch_end = epoch[0], epoch[1]\n",
    "        # Adjust the start of the epoch\n",
    "        current_point = epoch_start\n",
    "        acceleration_at_crossing=(speeds[current_point + 1] - speeds[current_point]) / (time_video_frames[current_point + 1] - time_video_frames[current_point])\n",
    "        while current_point > 0:\n",
    "            previous_acceleration = (speeds[current_point] - speeds[current_point - 1]) / (time_video_frames[current_point] - time_video_frames[current_point - 1])\n",
    "            if previous_acceleration <= (0.1 * acceleration_at_crossing) or previous_acceleration <= 0:\n",
    "                break\n",
    "            current_point -= 1\n",
    "            #print(f'it went backward on epoch {index}')\n",
    "        clean_run_epochs[index][0] = current_point\n",
    "\n",
    "    #Adjust the end of the epoch\n",
    "    #We are going forward after the speed crossed downward the speed threshold and find the point at wich the animal acceleration is less than 40% \n",
    "    #than the acceleration at the moment at which it passed the treshold. \n",
    "        current_point = epoch_end\n",
    "        acceleration_at_crossing=(speeds[current_point - 1] - speeds[current_point]) / (time_video_frames[current_point] - time_video_frames[current_point-1])\n",
    "        while current_point < len(speeds) - 1:\n",
    "            next_acceleration = (speeds[current_point] - speeds[current_point + 1]) / (time_video_frames[current_point+1] - time_video_frames[current_point])\n",
    "            if next_acceleration <= (0.1 * acceleration_at_crossing) or next_acceleration <= 0:\n",
    "                break\n",
    "            current_point += 1\n",
    "            #print(f'it went forward on epoch {index}')\n",
    "        clean_run_epochs[index][1] = current_point\n",
    "\n",
    "    \n",
    "   \n",
    "    return clean_run_epochs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_run_epochs = detect_run_epochs(speeds, time_video_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After splitting trajectory in run epochs we are going to refdefine these epochs depending on their start and end positions relative to the trapezes surrounding towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a function to detect if a position is in a polygon \n",
    "\n",
    "def is_point_in_polygon(polygon_vertices, point): # function to replace the not so efficient one points_in_polygon written originally (not by Alice :)\n",
    "    \"\"\"\n",
    "    Determine if a point is inside or outside a polygon.\n",
    "\n",
    "    Args:\n",
    "    - polygon_vertices: Coordinates of the polygon vertices [[Xa, Ya], [Xb, Yb], [Xc, Yc], [Xd, Yd]]\n",
    "    - point: Coordinates of the point to check [x, y]\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the point is inside the polygon, False otherwise\n",
    "    \"\"\"\n",
    "    path = Path(polygon_vertices)\n",
    "    return path.contains_point(point)\n",
    "\n",
    "\n",
    "# this check if a given position (run start or stop) is in a given trapze of a given tower\n",
    "# it returns true and false and if true which tower and trapze\n",
    "def check_position_in_trapezes(position, all_trapezes_coordinates):\n",
    "    \"\"\"\n",
    "    Check if the position is inside any of the trapezes.\n",
    "    :param position: Tuple (x, y) representing the position to check.\n",
    "    :param all_trapezes_coordinates: Dictionary containing trapezes coordinates.\n",
    "    :return: List [True, towerlabel, trapezelabel] if inside a trapeze, [False, 'none', 'none'] otherwise.\n",
    "    \"\"\"\n",
    "    for towerlabel, trapezes in all_trapezes_coordinates.items():\n",
    "        #print(towerlabel)\n",
    "        for trapezelabel, trapeze_coordinates in trapezes.items():\n",
    "            #print(trapezelabel)\n",
    "            #print(trapeze_coordinates)\n",
    "            if is_point_in_polygon(trapeze_coordinates,position):\n",
    "                return [True, towerlabel, trapezelabel]\n",
    "    return [False, None, None]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_epoch_types(clean_run_epochs, all_trapezes_coordinates_cm, smoothed_positions_cm, time_video_frames, turns_df):\n",
    "    # Initialize list to store run epochs with additional information\n",
    "    run_epochs_start_stop_Tower_Trapeze = []\n",
    "\n",
    "    # Iterate over each run epoch\n",
    "    for epoch_index, run_epoch in enumerate(clean_run_epochs):\n",
    "        run_epoch_start_stop_Tower_Trapeze = []\n",
    "        start_index, end_index = run_epoch[0], run_epoch[1]\n",
    "        run_epoch_start_stop_Tower_Trapeze.append(run_epoch)\n",
    "\n",
    "        # Get the starting and ending positions\n",
    "        starting_position = [smoothed_positions_cm[0][start_index], smoothed_positions_cm[1][start_index]]\n",
    "        ending_position = [smoothed_positions_cm[0][end_index], smoothed_positions_cm[1][end_index]]\n",
    "\n",
    "        # Check the starting and ending positions relative to trapeze and tower\n",
    "        for position_to_check in [starting_position, ending_position]:\n",
    "            in_trapeze_info = check_position_in_trapezes(position_to_check, all_trapezes_coordinates_cm)\n",
    "            run_epoch_start_stop_Tower_Trapeze.append(in_trapeze_info[1:])  # Append trapeze/tower start/stop info\n",
    "\n",
    "        run_epochs_start_stop_Tower_Trapeze.append(run_epoch_start_stop_Tower_Trapeze)\n",
    "\n",
    "    # Identify immobility epochs\n",
    "    immobility_epochs = []\n",
    "    for i in range(len(clean_run_epochs) - 1):\n",
    "        current_epoch_end = clean_run_epochs[i][1]\n",
    "        next_epoch_start = clean_run_epochs[i + 1][0]\n",
    "        \n",
    "        if current_epoch_end < next_epoch_start:\n",
    "            immobility_epochs.append([current_epoch_end, next_epoch_start])\n",
    "\n",
    "    # Initialize the all_epochs dictionary\n",
    "    all_epochs = {\n",
    "        'run_around_tower': [],\n",
    "        'run_between_towers': [],\n",
    "        'run_toward_tower': [],\n",
    "        'exploratory_run': [],\n",
    "        'immobility': []\n",
    "    }\n",
    "\n",
    "    # Classify each run epoch into different types\n",
    "    for run_epoch_start_stop_Tower_Trapeze in run_epochs_start_stop_Tower_Trapeze:\n",
    "        # Exploratory run if the end is not in a trapeze\n",
    "        if run_epoch_start_stop_Tower_Trapeze[2][0] is None:\n",
    "            all_epochs['exploratory_run'].append(run_epoch_start_stop_Tower_Trapeze)\n",
    "        # Run toward a tower if the start is outside a trapeze\n",
    "        elif run_epoch_start_stop_Tower_Trapeze[1][0] is None:\n",
    "            all_epochs['run_toward_tower'].append(run_epoch_start_stop_Tower_Trapeze)\n",
    "        # Run between towers if start and stop are in trapezes of different towers\n",
    "        elif run_epoch_start_stop_Tower_Trapeze[1][0] != run_epoch_start_stop_Tower_Trapeze[2][0]:\n",
    "            all_epochs['run_between_towers'].append(run_epoch_start_stop_Tower_Trapeze)\n",
    "        else:\n",
    "            # Check if the animal switched trapeze at least once\n",
    "            start_stop_times_run_epoch = [time_video_frames[run_epoch_start_stop_Tower_Trapeze[0][0]], time_video_frames[run_epoch_start_stop_Tower_Trapeze[0][1]]]\n",
    "            switch_in_turns_df = turns_df[(turns_df['time'] >= start_stop_times_run_epoch[0]) & (turns_df['time'] <= start_stop_times_run_epoch[1])]\n",
    "            num_trapeze_switches = switch_in_turns_df.shape[0]\n",
    "\n",
    "            # Run around the same tower if trapeze switching occurred\n",
    "            if num_trapeze_switches > 0:\n",
    "                all_epochs['run_around_tower'].append(run_epoch_start_stop_Tower_Trapeze)\n",
    "\n",
    "    # Add immobility epochs\n",
    "    all_epochs['immobility'] = immobility_epochs\n",
    "\n",
    "    return all_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs=define_epoch_types(clean_run_epochs, all_trapezes_coordinates_cm, smoothed_positions_cm, time_video_frames, turns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further analysis on turns around tower\n",
    "Find turns around tower and check if they were rewarded and  clockwise or counterclowise by using the turninfo dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_run_around_tower_epochs(all_epochs, time_video_frames, turns_df, distances, speeds):\n",
    "    # Create a deep copy of the list of runs around tower\n",
    "    runs_around_tower = copy.deepcopy(all_epochs['run_around_tower'])\n",
    "\n",
    "    # Iterate over each run in the 'run_around_tower' category\n",
    "    for run_index, run_around_tower in enumerate(runs_around_tower):\n",
    "        run_start_index = run_around_tower[0][0]\n",
    "        run_end_index = run_around_tower[0][1]\n",
    "        start_stop_times_run_epoch = [time_video_frames[run_start_index], time_video_frames[run_end_index]]\n",
    "        \n",
    "        # Find the relevant entries in turns_df within the run epoch\n",
    "        condition = (turns_df['time'] >= start_stop_times_run_epoch[0]) & (turns_df['time'] <= start_stop_times_run_epoch[1])\n",
    "        if not condition.any():\n",
    "            continue\n",
    "        \n",
    "        switch_in_turns_df = turns_df[condition]\n",
    "        num_trapezeswitch = switch_in_turns_df.shape[0]\n",
    "        \n",
    "        # Initialize the type_of_turn dictionary\n",
    "        type_of_turn = {'Rewarded': '', 'direction': '', 'num_trapezeswitch': num_trapezeswitch}\n",
    "        \n",
    "        # Normalize 'Rewarded' to boolean\n",
    "        rewarded_value = switch_in_turns_df.iloc[0]['Rewarded']\n",
    "        if rewarded_value in {'1', 'True', True}:\n",
    "            type_of_turn['Rewarded'] = True\n",
    "        elif rewarded_value in {'0', 'False', False}:\n",
    "            type_of_turn['Rewarded'] = False\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected value for Rewarded: {rewarded_value}\")\n",
    "        \n",
    "        # Determine turn direction\n",
    "        if switch_in_turns_df.iloc[0]['turnDirection'] == 270:\n",
    "            type_of_turn['direction'] = 'CW'\n",
    "        else:\n",
    "            type_of_turn['direction'] = 'CCW'\n",
    "        \n",
    "        # Append the type_of_turn information to the run\n",
    "        runs_around_tower[run_index].append(type_of_turn)\n",
    "        \n",
    "        # Extract the run epoch, compute kinematics\n",
    "        kinematics = {\n",
    "            'epoch_time': '',\n",
    "            'epoch_duration': '',\n",
    "            'epoch_distance': '',\n",
    "            'epoch_meanspeed': '',\n",
    "            'epoch_maxspeed': ''\n",
    "        }\n",
    "        \n",
    "        # Compute kinematic values\n",
    "        kinematics['epoch_time'] = time_video_frames[run_start_index]\n",
    "        kinematics['epoch_duration'] = start_stop_times_run_epoch[1] - start_stop_times_run_epoch[0]\n",
    "        kinematics['epoch_distance'] = np.sum(distances[run_start_index:run_end_index])\n",
    "        kinematics['epoch_meanspeed'] = kinematics['epoch_distance'] / kinematics['epoch_duration']\n",
    "        kinematics['epoch_maxspeed'] = np.max(speeds[run_start_index:run_end_index])\n",
    "        \n",
    "        # Append the kinematics information to the run\n",
    "        runs_around_tower[run_index].append(kinematics)\n",
    "\n",
    "    # Update the 'run_around_tower' epochs in all_epochs\n",
    "    all_epochs['run_around_tower'] = runs_around_tower\n",
    "    \n",
    "    return all_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs = process_run_around_tower_epochs(all_epochs, time_video_frames, turns_df, distances, speeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the total and rewarded number of clockwise, coutnerclockwise turns per object \n",
    "TODO sum duration and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_around_tower_resultssessions(all_epochs):\n",
    "    runs_around_tower = all_epochs['run_around_tower']\n",
    "    \n",
    "    # Initialize the dictionary to hold the results for each tower\n",
    "    run_around_tower_sessionresult = {\n",
    "        'NE': {'total_CW': 0, 'total_CCW': 0, 'rewarded_CW': 0, 'rewarded_CCW': 0},\n",
    "        'NW': {'total_CW': 0, 'total_CCW': 0, 'rewarded_CW': 0, 'rewarded_CCW': 0},\n",
    "        'SE': {'total_CW': 0, 'total_CCW': 0, 'rewarded_CW': 0, 'rewarded_CCW': 0},\n",
    "        'SW': {'total_CW': 0, 'total_CCW': 0, 'rewarded_CW': 0, 'rewarded_CCW': 0},\n",
    "        'All': {'total_CW': 0, 'total_CCW': 0, 'rewarded_CW': 0, 'rewarded_CCW': 0}\n",
    "    }\n",
    "\n",
    "    # Process each run in the data\n",
    "    for run in runs_around_tower:\n",
    "        _, start_info, end_info, type_of_turn, kinematics_of_turn = run\n",
    "        tower = start_info[0]\n",
    "        direction = type_of_turn['direction']\n",
    "        rewarded = type_of_turn['Rewarded']\n",
    "        \n",
    "        # Update counts based on direction\n",
    "        if direction == 'CW':\n",
    "            run_around_tower_sessionresult[tower]['total_CW'] += 1\n",
    "            run_around_tower_sessionresult['All']['total_CW'] += 1\n",
    "            if rewarded:\n",
    "                run_around_tower_sessionresult[tower]['rewarded_CW'] += 1\n",
    "                run_around_tower_sessionresult['All']['rewarded_CW'] += 1\n",
    "        elif direction == 'CCW':\n",
    "            run_around_tower_sessionresult[tower]['total_CCW'] += 1\n",
    "            run_around_tower_sessionresult['All']['total_CCW'] += 1\n",
    "            if rewarded:\n",
    "                run_around_tower_sessionresult[tower]['rewarded_CCW'] += 1\n",
    "                run_around_tower_sessionresult['All']['rewarded_CCW'] += 1\n",
    "\n",
    "    return run_around_tower_sessionresult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_around_tower_sessionresult=get_run_around_tower_resultssessions(all_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now computes kinematics info on the other type of turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_other_epochs(all_epochs, time_video_frames, smoothed_positions_cm, all_trapezes_coordinates_cm, distances, speeds):\n",
    "    \"\"\"\n",
    "    Process the other types of epochs ('run_between_towers', 'run_toward_tower', 'exploratory_run', 'immobility')\n",
    "    and compute kinematics for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    epoch_types=['run_around_tower','run_between_towers','run_toward_tower','exploratory_run','immobility']\n",
    "    for epoch_type in epoch_types[1:]:  # We skip 'run_around_tower' as it's already processed\n",
    "        print(f\"Processing {epoch_type} epochs...\")\n",
    "        epochs_to_analyze = copy.deepcopy(all_epochs[epoch_type])\n",
    "        \n",
    "        if epoch_type == 'immobility':\n",
    "            for epoch_index, epoch_to_analyze in enumerate(epochs_to_analyze):\n",
    "                epoch_start_index = epoch_to_analyze[0]\n",
    "                epoch_end_index = epoch_to_analyze[1]\n",
    "\n",
    "                # Compute kinematics for immobility epoch\n",
    "                kinematics = {\n",
    "                    'time': time_video_frames[epoch_start_index],\n",
    "                    'duration': time_video_frames[epoch_end_index] - time_video_frames[epoch_start_index],\n",
    "                    'position': [smoothed_positions_cm[0][epoch_start_index], smoothed_positions_cm[1][epoch_start_index]],\n",
    "                    'in_trapeze': check_position_in_trapezes(\n",
    "                        [smoothed_positions_cm[0][epoch_start_index], smoothed_positions_cm[1][epoch_start_index]], \n",
    "                        all_trapezes_coordinates_cm\n",
    "                    )[0]\n",
    "                }\n",
    "                epochs_to_analyze[epoch_index].append(kinematics)\n",
    "        \n",
    "        else:  # For other epoch types (run_between_towers, run_toward_tower, exploratory_run)\n",
    "            for epoch_index, epoch_to_analyze in enumerate(epochs_to_analyze):\n",
    "                epoch_start_index = epoch_to_analyze[0][0]\n",
    "                epoch_end_index = epoch_to_analyze[0][1]\n",
    "\n",
    "                # Compute kinematics for running epoch\n",
    "                kinematics = {\n",
    "                    'time': time_video_frames[epoch_start_index],\n",
    "                    'duration': time_video_frames[epoch_end_index] - time_video_frames[epoch_start_index],\n",
    "                    'distance': np.sum(distances[epoch_start_index:epoch_end_index]),\n",
    "                    'meanspeed': np.sum(distances[epoch_start_index:epoch_end_index]) / \n",
    "                                 (time_video_frames[epoch_end_index] - time_video_frames[epoch_start_index]),\n",
    "                    'maxspeed': np.max(speeds[epoch_start_index:epoch_end_index])\n",
    "                }\n",
    "                epochs_to_analyze[epoch_index].append(kinematics)\n",
    "\n",
    "        all_epochs[epoch_type] = epochs_to_analyze\n",
    "        \n",
    "\n",
    "    return all_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing run_between_towers epochs...\n",
      "Processing run_toward_tower epochs...\n",
      "Processing exploratory_run epochs...\n",
      "Processing immobility epochs...\n"
     ]
    }
   ],
   "source": [
    "all_epochs=process_other_epochs(all_epochs, time_video_frames, smoothed_positions_cm, all_trapezes_coordinates_cm, distances, speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
